{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Assignment: Multiple Regression\n",
    "# Day 14\n",
    "# CMSE 202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Put your name here</p>\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goals\n",
    "\n",
    "By the end of today's class, you'll have practiced:\n",
    "* Loading and manipulated fixed width column data\n",
    "* Replacing/removing missing data entries\n",
    "* Performing multiple regression using all features and a reduced set of statistically significant features.\n",
    "\n",
    "### Agenda for today's class:\n",
    "\n",
    "1. [Working with more unfamiliar data](#data)\n",
    "1. [Multiple Regression](#multiple-regression)\n",
    "1. [Visualization - How well does our model fit our data?](#viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\")\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"data\"></a>\n",
    "## 1. Working with more unfamiliar data \n",
    "\n",
    "We are going to work with some data generated by U.N.E.S.C.O. (United Nations Education, Scientific, and Cultural Organization) and data they collected relating to poverty and inequality in the world. There are two files you need to do the work:\n",
    "\n",
    "- `poverty.dat` which is the data file itself\n",
    "- `poverty.txt` which describes the data columns as **fixed width column** data. That is, this file describes the columns of the data for each category. For example, the data in columns 1-6 of `poverty.dat` contain the \"live birth rates per 1,000 population\".\n",
    "\n",
    "You can download the files from here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/poverty.dat`\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/poverty.txt`\n",
    "\n",
    "### How does one deal with a \"fixed width column\" data file?\n",
    "\n",
    "Conveniently there is a fixed width column pandas data reader. Look it up and read in the data. **Check with your group members to make sure every can find the right function to use!**\n",
    "\n",
    "Again we find ourselves with a data file does doesn't contain any column headers (argh!).  Take a look at the `poverty.txt` file for column information and give the columns in your Pandas DataFrame short, but useful names.\n",
    "\n",
    "**&#9989; Do This:** Read the data into a DataFrame and display the `head()` of the DataFrame. Remember that you can set the column labels by setting the `.columns` attribute to a list with the appropriate column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining the \"type\" of the data\n",
    "\n",
    "**&#9989; Questions:**  Now look at the `.dtypes` of your DataFrame and comment on anything that doesn't immediately make sense to you. Do all of the columns have a type that matches your expectations? If not, what is it about the values in the DataFrame that is causing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Handling missing data - Imputation\n",
    "\n",
    "Let's face it, sometimes data is bad. Values are not recorded, or are mis-recorded, or are so far outside of your expectations that you suspect that there is something wrong. On the other hand, just **changing** the data seems like cheating. We have to work with what we have, and if we have to make changes it would be good to do that programmatically so that it is recorded for others to see. \n",
    "\n",
    "The process of <a href=\"https://en.wikipedia.org/wiki/Imputation_(statistics)\"> imputation </a> is the statistical replacement of missing/bad data with substitute values.\n",
    "\n",
    "**It turns out that we have a case of missing data in our dataset!** In the **Gross National Product (GNP)** column some of the values are set to \" \\* \" indicating missing data. When Pandas reads in the column the only type that makes sense when both characters _and_ numbers are present is a string. Therefore Pandas chose to set the type to `object` instead of the expected `int64` or `float64`.\n",
    "\n",
    "#### Using `numpy.nan` as a replacement\n",
    "\n",
    "For better or worse, pandas assumes that \"bad values\" will be marked in the data as **NaN** which it can then represent using [NumPy's \"`nan`\"](https://numpy.org/doc/stable/reference/constants.html#numpy.nan). NaN is short for \"Not a Number\".\n",
    "\n",
    "**If we can mark the missing data with \"NaN\" instead of \"\\*\", we will have access to some of the imputation methods, which would allow us to replacing the NaN values with various substitution values (e.g. mean, median, specific value, etc.)**. \n",
    "\n",
    "There are (at least) **two ways** to do this:\n",
    "1. You can do a `.replace` on the column using a dictionary of the form \"{value to replace : new value, ...}\". If you do this, **remember to save the result**. After you do this, you'll still need to change the column type from \"object\" to a \"float64\" in order to assure that the values are numeric values. Note that you cannot convert a `np.nan` to an integer but you can to a float.\n",
    "2. You can convert the everything that can be converted to a number using the Pandas `.to_numeric()` function. Conveniently if you use the \"`errors`\" argument in the function you can force Pandas to convert any non-numbers to \"`np.nan`\" values. As with the previous method, you need to save the converted column in place of the column with the \"\\*\" entries. This option has the benefit of not requiring an additional step of having to manually change the data type!\n",
    "\n",
    "**&#9989; Do This:** Convert the missing entries in the GNP column to `np.nan` values and show the head of your modified DataFrame to ensure that the \"NaN\" values are showing up. Also print the `dtypes` to show that the column has changed type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing np.nan values\n",
    "\n",
    "Now that \"bad values\" are marked as `numpy.nan`, we can use the DataFrame method `fillna` to change those values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df[\"GNP\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell returns a new DataFrame where all the `np.nan` values in the GNP column are replaced with 0.\n",
    "\n",
    "You can do other things are well, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways of accomplishing the same thing:\n",
    "\n",
    "# Change the values in the series object (the column) directly\n",
    "poverty_df[\"GNP\"].fillna(poverty_df[\"GNP\"].mean())\n",
    "\n",
    "# Changes the value of the series object (the column) by accessing the full dataframe and using a dictionary to reference the column\n",
    "poverty_df.fillna({\"GNP\": poverty_df[\"GNP\"].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both of the lines in the above cell do the same thing**. The first version changes any `np.nan` in the `GNP` column to be the mean of the column. The second takes a dictionary where the the key of the dictionary is the column to change and the value is what to replace the `np.nan` with. Note you could replace with other values like: median, min, max, or some other fixed value.\n",
    "\n",
    "Remember that all of these examples return either a new Series (when working with just a column) or a DataFrame (if working with the entire element). Nothing is changed in the original unless you assign the result or use `inplace=True` in the call.\n",
    "\n",
    "Finally, if you decide that the right thing to do is **remove** any row with a `np.nan` value, we can use the `.dropna` method of DataFrames as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poverty_df)\n",
    "poverty_df_dropped = poverty_df.dropna()\n",
    "print(len(poverty_df), len(poverty_df_dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you think?\n",
    "\n",
    "**&#9989; Do This:** Discuss with your group what you think is the best thing to do with the \"bad values\" in the DataFrame given the discussion above. Make a collective decision and record it below. Once you've come to a decision, modify your dataset accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"multiple-regression\"></a>\n",
    "## 2. Multiple Regression\n",
    "\n",
    "In the past, we have limited ourselves to using a single feature or independent variable to fit a line or, as in the pre-class, created additional features based on our original feature to fit a polynomial. However, **we can just as easily use all, or some combination of all, the features available our dataset** to make a OLS model. This is referred to as multiple regression (you can see a brief introduction [here](https://medium.com/swlh/understanding-multiple-linear-regression-e0a93327e960)). The question is, **is it a good idea to just use all the possible features available to make a model?**\n",
    "\n",
    "**&#9989; Do This:** Discuss this idea with your group and record your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Infant Mortality model\n",
    "\n",
    "Using the U.N.E.S.C.O. data, we can make a model of \"Infant Mortality\" as the dependent variable against all the other available features. As a hint, an easy way to do this is the make the `sm.OLS` model with  \"Infant Mortality\" as the first argument (the dependent variable) and then the entire DataFrame where \"Infant Mortality\" is dropped as the second argument. **You should also drop the \"Country\" column as unique strings don't play well in basic linear models.**\n",
    "\n",
    "**&#9989; Do This:** Make an OLS model that predicts \"Infant Mortality\" using the other variables (making sure to drop the \"Country\" column as well) and display the `.summary()` of that process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several interesting things about this `.summary()`. Let's start with things you have seen before.\n",
    "\n",
    "**&#9989; Do This:** Look for the adjusted $R^2$ statistic. What does this adjusted $R^2$ tell you about how well your model fits your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at something new, **the \"P\" values** associated with the features used in the model. [P values](https://en.wikipedia.org/wiki/P-value) are used widely in statisical testing to judge if a result is statistically significant. Those P values that are 0 (or typically less 0.05) indicate a feature that is \"significant\" in its ability to predict the dependent variable. Those larger than 0.05 are less significant. Of course, one should be cautious with relying solely on P-values as they can be [misused](https://en.wikipedia.org/wiki/Misuse_of_p-values) and [p-hacking](https://en.wikipedia.org/wiki/Data_dredging) (intentional or not) can lead to misleading results.\n",
    "\n",
    "**&#9989; Do This:** With a healthy dose of caution in mind, review your P-values. The values you get will depend on what you did with your \"bad values\", but list below the top three \"most significant\" features and the overall Adjusted R-squared using all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A \"reduced\" model using only the \"significant\" features\n",
    "\n",
    "Modeling data is as much a craft as it is a science. We often seek the simplest models that explain or data well because they are typically more interpretable, easier to explain, and provide the information on the main influences of the system we are studying. There are reasons we might want a more complex model to capture the details and the nuance of the system. But for the U.N.E.S.C.O. data that we have, we are likely able to capture most of the system using a smaller number of features. _These ideas are related to the pre-class modeling you did with increasingly higher powers of `x`._\n",
    "\n",
    "**&#9989; Do This:** Redo the model with only the top three features you found above vs \"Infant Mortality\". Display the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Review this model and the one you constructed earlier in the notebook. Report how the Adjusted R-squared value changed from using only the top three vs using all the available features. How well does this reduced model appear to fit your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"viz\"></a>\n",
    "## 3. Visualization - How well does our model fit our data?\n",
    "\n",
    "We have been checking how our models fit our data using both plots of the fitted values and the residuals. These plots are generated from the information stored in [various attributes of the OLS results object](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.html). We will continue to use the top two plots from `.graphics.plot_regress_exog` to investigate our fits. But you could also construct the plots directly using the attributes of the OLS results object.\n",
    "\n",
    "**Note that you will need one plot for each feature in the model as each figure is only produced for a given choice of feature.**\n",
    "\n",
    "**&#9989; Do This:** Create three `.graphics.plot_regress_exog` figures, one for each of the features in your reduced model. Pay special attention to the top two plots: the fitted values figure and the residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Questions:** Based on these figures, how well does it appear your reduced model fit your data? Do you have any concerns about the distribution of the residuals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"viz\"></a>\n",
    "## 4. Symbolic Regression - Searching for both model structure and parameters!\n",
    "\n",
    "So far we've been exploring scenarios where we have a model structure and the goal is to fit the model to some data by finding the parameter values that lead to the best fit. While this works great if we know the model structure, in cases where we don't know the model structure, we don't want to be left guessing and checking many different structure. Rather, we can let the computer automatically search for the best model structure for us. \n",
    "\n",
    "This combined search for both the model structure and parameters is called Symbolic Regression. \n",
    "\n",
    "In this section we will explore StackGP ([StackGP Documentation](https://hoolagans.github.io/StackGP-Documentation/)), a Python package for Symbolic Regression, to see how we can find a model that fits data when we don't know the correct model structure. \n",
    "\n",
    "**Note: this exercise is just for fun. You will not be tested on your knowledge of symbolic regression. Although, you may choose to use it in your course project if it makes sense.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** First use pip install to install StackGP. `pip install StackGP` or `pip install --user StackGP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Make a scatter plot using the data in the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import StackGP as sgp\n",
    "import matplotlib.pyplot as plt\n",
    "x=np.array([[1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2,\n",
    "        2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5,\n",
    "        3.6, 3.7, 3.8, 3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8,\n",
    "        4.9, 5. , 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1,\n",
    "        6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4,\n",
    "        7.5, 7.6, 7.7, 7.8, 7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7,\n",
    "        8.8, 8.9, 9. , 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]])\n",
    "y=np.array([42.44135808, 41.20429358, 40.06103995, 39.0029947 , 38.02249497,\n",
    "       37.11269916, 36.26748529, 35.48136346, 34.74940027, 34.06715341,\n",
    "       33.43061493, 32.83616182, 32.28051306, 31.76069195, 31.27399325,\n",
    "       30.81795425, 30.39032942, 29.98906797, 29.61229414, 29.25828969,\n",
    "       28.92547844, 28.61241251, 28.31776005, 28.04029442, 27.77888439,\n",
    "       27.53248546, 27.30013212, 27.08093081, 26.87405365, 26.67873284,\n",
    "       26.49425552, 26.31995922, 26.15522768, 25.99948711, 25.8522028 ,\n",
    "       25.712876  , 25.58104116, 25.45626332, 25.33813586, 25.22627828,\n",
    "       25.12033436, 25.01997034, 24.92487328, 24.83474962, 24.74932377,\n",
    "       24.66833691, 24.59154578, 24.51872164, 24.44964933, 24.38412631,\n",
    "       24.32196185, 24.26297627, 24.2070002 , 24.15387398, 24.10344696,\n",
    "       24.055577  , 24.01012991, 23.96697899, 23.92600454, 23.88709345,\n",
    "       23.8501388 , 23.81503951, 23.78169997, 23.75002973, 23.71994321,\n",
    "       23.6913594 , 23.66420161, 23.6383972 , 23.61387741, 23.59057706,\n",
    "       23.56843443, 23.54739099, 23.52739129, 23.50838274, 23.49031551,\n",
    "       23.47314232, 23.45681832, 23.44130099, 23.42654998, 23.41252699,\n",
    "       23.3991957 , 23.38652164, 23.37447206, 23.36301591, 23.3521237 ,\n",
    "       23.34176742, 23.33192048, 23.32255764, 23.31365491, 23.30518953])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question:** Based on the scatter plot of the data, do you have a guess as to what the model structure might be? Make your best guess and write out the equation below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do this - Erase this and put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Now remake the scatter plot from above, but add in a line or points representing the model from your guess to see how close you got with your guess. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Now lets use Symbolic Regression to search for a model. Just run the code below and the search will begin. (Note: this may take a few seconds since it has to search a lot of model structures). You should see a plot showing the learning curve of the search after it completes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sgp.evolve(x,y,tracking=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Now run the following code to see the equation that was discovered by the search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.printGPModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Now take a look at the documentation for `plotModelResponseComparison`. Use the plotting function to see how well the model fits the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Run the following code. This will display the ground truth equation that was used to generate the training data. Did the model search find a similar model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthModel=[np.array([sgp.exp, sgp.sqrt, sgp.inv, 'pop', sgp.add, sgp.exp], dtype=object),\n",
    " [sgp.variableSelect(0),\n",
    "  3.141592653589793],\n",
    " [np.float64(0.0), 9]]\n",
    "sgp.printGPModel(truthModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** Now lets try fitting the data from part 2 where the country column was dropped. Note: the data frame with the input features will need to be transposed since the `evolve` function expects each feature to be a row. You can easily transpose a data frame by doing something like `dfT = df.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Do This:** The following code will take the model you evolved and display it using the variable names from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols\n",
    "sgp.printGPModel(model,symbols([\"BirthRate\", \n",
    "        \"DeathRate\",  \n",
    "        \"LifeExpectancyM\", \n",
    "        \"LifeExpectancyF\", \n",
    "        \"GNP\", \n",
    "        \"Group\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, you're done with your in-class assignment!\n",
    "\n",
    "Now, you just need to submit this assignment by uploading it to the course <a href=\"https://d2l.msu.edu/\">Desire2Learn</a> web page for today's submission folder (Don't forget to add your names in the first cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &#169; Copyright 2025,  Department of Computational Mathematics, Science and Engineering at Michigan State University\n",
    "\n",
    "<!-- 9/16/2024 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
